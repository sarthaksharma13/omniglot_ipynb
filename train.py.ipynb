{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as dset\n",
    "from torchvision import transforms\n",
    "from mydataset import OmniglotTrain, OmniglotTest\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from model import Siamese\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import args\n",
    "# Parse commandline arguements\n",
    "cmd = args.arguments;\n",
    "\n",
    "# Check if cuda is available for GPU usage.\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomAffine(15),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Assuming you have run make_dataset.py as specified.\n",
    "train_path = 'background'\n",
    "test_path = 'evaluation'\n",
    "train_dataset = dset.ImageFolder(root=train_path)\n",
    "test_dataset = dset.ImageFolder(root=test_path)\n",
    "\n",
    "way = 20\n",
    "times = 400\n",
    "\n",
    "dataSet = OmniglotTrain(train_dataset, transform=data_transforms)\n",
    "testSet = OmniglotTest(test_dataset, transform=transforms.ToTensor(), times = times, way = way)\n",
    "testLoader = DataLoader(testSet, batch_size=way, shuffle=False, num_workers=16)\n",
    "\n",
    "dataLoader = DataLoader(dataSet, batch_size=cmd.trainBatch,\\\n",
    "                        shuffle=False, num_workers=16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the network architecture\n",
    "net = Siamese()\n",
    "# Loss criterion\n",
    "criterion = torch.nn.BCEWithLogitsLoss(size_average=True)\n",
    "\n",
    "# Optimizer\n",
    "if cmd.optMethod == 'adam':\n",
    "    optimizer = torch.optim.Adam(net.parameters(),lr = cmd.lr )\n",
    "\n",
    "# To store train loss\n",
    "train_loss = []\n",
    "# Get the network in training mode.\n",
    "net.train()\n",
    "\n",
    "# Use GPUs.\n",
    "if cuda:\n",
    "    net.cuda()\n",
    "\n",
    "# Parameters to show, save and test\n",
    "show_every = 10\n",
    "save_every = 100\n",
    "test_every = 100\n",
    "\n",
    "# Track the loss\n",
    "loss_val = 0\n",
    "\n",
    "\n",
    "for batch_id, (img1, img2, label) in enumerate(dataLoader, 1):\n",
    "    # Max iters \n",
    "    if batch_id > cmd.iters:\n",
    "        break\n",
    "    # Start time\n",
    "    batch_start = time.time()\n",
    "\n",
    "    # If GPU, convert to cuda tensor\n",
    "    if cuda:\n",
    "        img1, img2, label = Variable(img1.cuda()), Variable(img2.cuda()), Variable(label.cuda())\n",
    "    else:\n",
    "        img1, img2, label = Variable(img1), Variable(img2), Variable(label)\n",
    "\n",
    "    # Zero gradient parameters from previous batch\n",
    "    optimizer.zero_grad()\n",
    "    # Forward the image\n",
    "    output = net.forward(img1, img2)\n",
    "    # Compute the loss\n",
    "    loss = criterion(output, label)\n",
    "\n",
    "    loss_val += loss.data[0]\n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "    # Take the optimizer step\n",
    "    optimizer.step()\n",
    "    # For saving, displaying and testing.\n",
    "    if batch_id % show_every == 0 :\n",
    "        print('[%d]\\tloss:\\t%.5f\\tTook\\t%.2f s'%(batch_id, loss_val/show_every, (time.time() - batch_start)*show_every))\n",
    "        loss_val = 0\n",
    "    if batch_id % save_every == 0:\n",
    "        torch.save(net.state_dict(), './model/model-batch-%d.pth'%(batch_id+1,))\n",
    "    if batch_id % test_every == 0:\n",
    "        right, error = 0, 0\n",
    "        for _, (test1, test2) in enumerate(testLoader, 1):\n",
    "            if cuda:\n",
    "                test1, test2 = test1.cuda(), test2.cuda()\n",
    "            test1, test2 = Variable(test1), Variable(test2)\n",
    "            output = net.forward(test1, test2).data.cpu().numpy()\n",
    "            pred = np.argmax(output)\n",
    "            if pred == 0:\n",
    "                right += 1\n",
    "            else: error += 1\n",
    "        print('*'*70)\n",
    "        print('[%d]\\tright:\\t%d\\terror:\\t%d\\tprecision:\\t%f'%(batch_id, right, error, right*1.0/(right+error)))\n",
    "        print('*'*70)\n",
    "\n",
    "    train_loss.append(loss_val)\n",
    "\n",
    "\n",
    "with open('train_loss', 'wb') as f:\n",
    "    pickle.dump(train_loss, f)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
